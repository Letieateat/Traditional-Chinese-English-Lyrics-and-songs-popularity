# -*- coding: utf-8 -*-
"""02Lyrics & Popularity_English Lyrics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k-AGT9ezgJlpcoLA9JOLklKYOvinGcHu

##Lyrics & Popularity (English)
1. Use Spotify and Genius API to get lyrics and song data in English
(Need to create a virtual environment (python 3.7) to use lyricsgenius)
2. Clean the data and tokenization
"""

!pip install spotipy --upgrade
!pip install lyricsgenius
!pip install pandas
!pip install spaCy
!python -m spacy download en_core_web_sm

import spotipy
from spotipy.oauth2 import SpotifyClientCredentials
import csv
import lyricsgenius
import pandas as pd
import spacy
import re

# Spotify Authentication
client_credentials_manager = SpotifyClientCredentials(client_id='Your client ID', client_secret='Your client secret')#replace the client id and secret with yours
sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)

# Extracting track URIs from the playlist
playlist_link = "https://open.spotify.com/playlist/6UeSakyzhiEt4NB3UAd6NQ?si=12ba6555446b416d" # Billboard Hot 100 English songs on Spotify
playlist_URI = playlist_link.split("/")[-1].split("?")[0]
track_uris = [x["track"]["uri"] for x in sp.playlist_tracks(playlist_URI)["items"]]

genius = lyricsgenius.Genius("Your genius API")#replace the token with yours

# for processing the text
nlp = spacy.load("en_core_web_sm")

# get stopwords in English
stopwords = spacy.lang.en.stop_words.STOP_WORDS

# create the dataset
with open('EN_songs.csv', mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Track Name', 'Artist Name', 'Artist Popularity', 'Artist Genres', 'Album', 'Popularity', 'Track Features', 'Lyrics'])

    # iteration
    for track in sp.playlist_tracks(playlist_URI)["items"]:
        # get song data from Spotify
        track_info = track["track"]
        track_name = track_info["name"]
        artist_name = track_info["artists"][0]["name"]
        artist_uri = track_info["artists"][0]["uri"]
        artist_info = sp.artist(artist_uri)
        artist_popularity = artist_info["popularity"]
        artist_genres = ', '.join(artist_info["genres"])
        album = track_info["album"]["name"]
        track_popularity = track_info["popularity"]
        track_features = sp.audio_features(track_info["uri"])[0]

        # get lyrics by using lyricsgenius
        song = genius.search_song(track_name, artist_name)

        # If lyrics are found, clean and tokenize them
        if song:
            # clean the lyrics
            lyrics = song.lyrics
            doc = nlp(lyrics)
            cleaned_lyrics = ' '.join([token.text for token in doc if token.text.lower() not in stopwords])
            cleaned_lyrics = re.sub('\[.*?\]', '', cleaned_lyrics, flags=re.MULTILINE)#remove patterns such as [Chorus]
            cleaned_lyrics = re.sub('[^\w\s]', '', cleaned_lyrics, flags=re.MULTILINE)#remove non-alphabets
            cleaned_lyrics = re.sub('^.*Contributors.*$', '', cleaned_lyrics, flags=re.MULTILINE)#remove introduction of composer

        else:
            # If lyrics are not found, set to "Lyrics not found"
            lyrics = "Lyrics not found"
            cleaned_lyrics = ""

        # write song information and lyrics to CSV file
        track_popularity=track_popularity/100 # Normalize popularity, convert the original numbers into scales from 0 to 1
        writer.writerow([track_name, artist_name, artist_popularity, artist_genres, album, track_popularity, track_features, cleaned_lyrics])

"""##Lyrics & Popularity (English)
3. Visualization (Need to disactivate the virtual environment)
"""

#Need to disactivate the virtual environment, install and import library again, because we can only use umap in new version
!pip install umap-learn #for dimension reduction
!pip install pandas
!pip install nltk

from umap import UMAP #for dimension reduction
from sklearn.feature_extraction.text import CountVectorizer ##convert token frequency into numerical matrix
from scipy.stats import pearsonr #to calculate the correlation
import matplotlib.pyplot as plt
import pandas as pd
import nltk

# read the data
df = pd.read_csv('https://raw.githubusercontent.com/Letieateat/Traditional-Chinese-English-Lyrics-and-songs-popularity/main/song-data/EN_songs.csv')


# Vectorize the tokenized lyrics
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['Lyrics'])

# Perform UMAP to reduce dimensionality
umap = UMAP(n_components=2, random_state=42)
X_umap = umap.fit_transform(X.toarray())

# Get the correlation between token frequency and Track Popularity
correlations = []
for i in range(X.shape[1]):
    correlation, _ = pearsonr(X[:, i].toarray().ravel(), df['Popularity'])
    correlations.append(correlation)

# Calculate the correlation between UMAP components and Track Popularity
correlation_x, _ = pearsonr(X_umap[:, 0], df['Popularity'])
correlation_y, _ = pearsonr(X_umap[:, 1], df['Popularity'])

# Plot tokens in reduced space along with their correlation values
plt.figure(figsize=(10, 8))
plt.scatter(X_umap[:, 0], X_umap[:, 1], c=df['Popularity'], cmap='GnBu', alpha=0.7)


# Add annotations for each point
nltk.download('words')
english_words = set(nltk.corpus.words.words())
non_numeric_features = [name for name in vectorizer.get_feature_names_out() if name.isalpha() and name.lower() in english_words] #use English words as annotation
for i, txt in enumerate(df['Lyrics']):
  plt.annotate(non_numeric_features[i], (X_umap[i, 0], X_umap[i, 1]), fontsize=8)

plt.colorbar(label='Popularity')
plt.xlabel('UMAP Component 1 (Correlation: {:.2f})'.format(correlation_x))
plt.ylabel('UMAP Component 2 (Correlation: {:.2f})'.format(correlation_y))
plt.title('English Tokens in Reduced Space with Correlation to Popularity')
plt.show()